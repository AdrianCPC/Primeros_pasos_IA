{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6YtjUnFD4r3VoLZxW9xNG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdrianCPC/Primeros_pasos_IA/blob/main/NLP_Corrector_Ortografico.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importar el corpus"
      ],
      "metadata": {
        "id": "MawrXgB6jiED"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ob9ZYN_-Vbk",
        "outputId": "411b0738-912c-4710-88d5-0db48aacc25a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\"HTTP: Diferencias entre GET y POST \"\n",
            "2020-10-21\n",
            "\"Vea las diferencias entre los métodos GET y POST de HTTP. Consulta la funcionalidad de cada uno y cuándo usarlos en la web.\"\n",
            "\"yuri-oliveira\"\n",
            "\"yuri.oliveira@alura.com.br\"\n",
            "\"front-end\"\n",
            "\n",
            "Cuando vamos a acceder a un sistema web, es bastante común pasar por una pantalla de inicio de sesión, en la que ponemos nuestras credenciales para acceder al sistema.\n",
            "Estas informaciones deben ser confidenciales, sin embargo, cuando intenté iniciar sesión en una ap\n"
          ]
        }
      ],
      "source": [
        "with open('textos_articulo.txt', 'r') as f:\n",
        "  articulos = f.read()\n",
        "  print(articulos[:500])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Separando palabras"
      ],
      "metadata": {
        "id": "YODdXBtKjl4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto_ejemplo = ' hola que tal'\n",
        "print(len(texto_ejemplo))\n",
        "palabras = texto_ejemplo.split()\n",
        "print(len(palabras))\n",
        "print(palabras)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghaoyZ_G_crP",
        "outputId": "62847643-928b-4ce9-823b-022386b51f1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13\n",
            "3\n",
            "['hola', 'que', 'tal']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto_ejemplo = ' hola critian, ¿que tal?'\n",
        "print(len(texto_ejemplo))\n",
        "palabras = texto_ejemplo.split()\n",
        "print(len(palabras))\n",
        "print(palabras)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxDunWfS_ui0",
        "outputId": "30c82706-a777-475b-ee13-1e9c62f73278"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24\n",
            "4\n",
            "['hola', 'critian,', '¿que', 'tal?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizando para analizar cada palabra, pero aun con split que no permite separar de caractes especiales\n",
        "texto_ejemplo = ' hola critian, ¿que tal?'\n",
        "print(len(texto_ejemplo))\n",
        "tokens = texto_ejemplo.split()\n",
        "print(len(tokens))\n",
        "print(tokens)"
      ],
      "metadata": {
        "id": "d-F4f1q4AD3H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "234570f2-bb07-4d14-d0ba-08d410cd5a22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24\n",
            "4\n",
            "['hola', 'critian,', '¿que', 'tal?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo que aprendimos en esta aula:\n",
        "\n",
        "El concepto de Procesamiento de Lenguaje Natural (PLN o NLP)\n",
        "\n",
        "En qué consiste un corrector ortográfico\n",
        "\n",
        "Cómo leer un archivo de texto usando python\n",
        "\n",
        "Separar las palabras usando split()"
      ],
      "metadata": {
        "id": "MAekAm5MD0wN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tokenizacion"
      ],
      "metadata": {
        "id": "h1YbysBSjrcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Px8CG-uTjtqK",
        "outputId": "c249d2a3-fc69-41ae-c6f8-6bde1d770548"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "palabras_separadas = nltk.tokenize.word_tokenize(texto_ejemplo) #para ingles\n",
        "print(palabras_separadas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyhuteJNj6ej",
        "outputId": "ab976cef-f778-4162-cc81-e251d5f6c71f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hola', 'critian', ',', '¿que', 'tal', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize.toktok import ToktokTokenizer   #usa las funciones en espanol"
      ],
      "metadata": {
        "id": "8yxUKVxEkYpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "toktok = ToktokTokenizer()\n",
        "palabras_separadas = toktok.tokenize(texto_ejemplo)\n",
        "print(palabras_separadas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcGM3P-fkqdz",
        "outputId": "19199a81-156c-4300-cfa0-be33b3e9b577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hola', 'critian', ',', '¿', 'que', 'tal', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(palabras_separadas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybWBcQukk5qj",
        "outputId": "406b1ea8-1844-45b1-f093-e29ca476add1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Excluyendo caracteres y puntuaciones"
      ],
      "metadata": {
        "id": "Yd4YGdVllcYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def separa_palabras(lista_tokens):\n",
        "  lista_palabras = []\n",
        "  for token in lista_tokens:\n",
        "    if token.isalpha():\n",
        "      lista_palabras.append(token)\n",
        "  return lista_palabras     #contabilizar cuantas palabras en el corpus se tiene"
      ],
      "metadata": {
        "id": "DplCogUUlWRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "separa_palabras(palabras_separadas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KM5POVDmIQb",
        "outputId": "d2b263b8-1d17-474f-96dd-724128ec5359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hola', 'critian', 'que', 'tal']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Contando palabras del corpus"
      ],
      "metadata": {
        "id": "XuTKFYXom93L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "palabras_separadas = toktok.tokenize(articulos)\n",
        "lista_palabras = separa_palabras(palabras_separadas)"
      ],
      "metadata": {
        "id": "j4ZDAHzImV1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'La cantidad de palabras en el corpus es de : {len(lista_palabras)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0LZ-rkKnltN",
        "outputId": "3cf9538d-7f4c-4c9a-a340-e54ed6a7f602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La cantidad de palabras en el corpus es de : 40052\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lista_palabras[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fi7OwjTfn3Li",
        "outputId": "f7f6dfdc-ff70-42af-d080-12e9dbbe0e41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['HTTP',\n",
              " 'Diferencias',\n",
              " 'entre',\n",
              " 'GET',\n",
              " 'y',\n",
              " 'POST',\n",
              " 'Vea',\n",
              " 'las',\n",
              " 'diferencias',\n",
              " 'entre',\n",
              " 'los',\n",
              " 'métodos',\n",
              " 'GET',\n",
              " 'y',\n",
              " 'POST',\n",
              " 'de',\n",
              " 'Consulta',\n",
              " 'la',\n",
              " 'funcionalidad',\n",
              " 'de']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Normalizando y eliminando duplicados"
      ],
      "metadata": {
        "id": "iRifwq0foMVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalizar(lista_palabras):\n",
        "  lista_normalizada = []\n",
        "\n",
        "  for palabra in lista_palabras:\n",
        "    lista_normalizada.append(palabra.lower())\n",
        "\n",
        "  return lista_normalizada"
      ],
      "metadata": {
        "id": "CEHJoU2ioZli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "palabras_normalizadas = normalizar(lista_palabras)\n",
        "print(palabras_normalizadas[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QLuIosno2xt",
        "outputId": "5ba6ae66-5305-4c7d-ffe3-a5087266a84c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['http', 'diferencias', 'entre', 'get', 'y', 'post', 'vea', 'las', 'diferencias', 'entre', 'los', 'métodos', 'get', 'y', 'post', 'de', 'consulta', 'la', 'funcionalidad', 'de']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#eliminacion duplicados\n",
        "\n",
        "palabras_unicas = set(palabras_normalizadas)\n",
        "print(len(palabras_unicas))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d84UDFlrpG4t",
        "outputId": "85b166cc-1e64-4633-8edc-ee0059ebb1e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo que aprendimos en esta aula:\n",
        "\n",
        "El concepto de tokenización\n",
        "\n",
        "A realizar el proceso de tokenización con las bibliotecas NLTK y toktok\n",
        "\n",
        "Separar caracteres alfabéticos de caracteres especiales con isalpha()\n",
        "\n",
        "Contar caracteres y palabras usando len()\n",
        "\n",
        "Proceso de Normalización con lower()\n",
        "\n",
        "Eliminar duplicados y repetidos con set()"
      ],
      "metadata": {
        "id": "LZ5888J1psIs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Operacion de adicion"
      ],
      "metadata": {
        "id": "omM31LJWiNw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#generar partes\n",
        "\n",
        "\n",
        "\n",
        "def adicionar_letras(partes):\n",
        "  letras = 'abcdefghijklmnñopqrstuvwxyzáéíóú'\n",
        "  nuevas_palabras = []\n",
        "\n",
        "  for I,D in partes:\n",
        "    for letra in letras:\n",
        "      nuevas_palabras.append(I + letra + D)\n",
        "  return nuevas_palabras\n",
        "\n",
        "\n",
        "def generar_palabras(palabra):\n",
        "  partes = []\n",
        "  for i in range(len(palabra)+1):\n",
        "    partes.append((palabra[:i],palabra[i:]))\n",
        "    palabras_generadas = adicionar_letras(partes)\n",
        "  return palabras_generadas\n",
        "\n"
      ],
      "metadata": {
        "id": "eKnEPySciOOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "palabra = 'lgica'\n",
        "palabras_generadas = generar_palabras(palabra)\n",
        "print(palabras_generadas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_40eW_SBnxVj",
        "outputId": "9243a663-4c9f-4dda-b5d1-6be6d9e9be90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['algica', 'blgica', 'clgica', 'dlgica', 'elgica', 'flgica', 'glgica', 'hlgica', 'ilgica', 'jlgica', 'klgica', 'llgica', 'mlgica', 'nlgica', 'ñlgica', 'olgica', 'plgica', 'qlgica', 'rlgica', 'slgica', 'tlgica', 'ulgica', 'vlgica', 'wlgica', 'xlgica', 'ylgica', 'zlgica', 'álgica', 'élgica', 'ílgica', 'ólgica', 'úlgica', 'lagica', 'lbgica', 'lcgica', 'ldgica', 'legica', 'lfgica', 'lggica', 'lhgica', 'ligica', 'ljgica', 'lkgica', 'llgica', 'lmgica', 'lngica', 'lñgica', 'logica', 'lpgica', 'lqgica', 'lrgica', 'lsgica', 'ltgica', 'lugica', 'lvgica', 'lwgica', 'lxgica', 'lygica', 'lzgica', 'lágica', 'légica', 'lígica', 'lógica', 'lúgica', 'lgaica', 'lgbica', 'lgcica', 'lgdica', 'lgeica', 'lgfica', 'lggica', 'lghica', 'lgiica', 'lgjica', 'lgkica', 'lglica', 'lgmica', 'lgnica', 'lgñica', 'lgoica', 'lgpica', 'lgqica', 'lgrica', 'lgsica', 'lgtica', 'lguica', 'lgvica', 'lgwica', 'lgxica', 'lgyica', 'lgzica', 'lgáica', 'lgéica', 'lgíica', 'lgóica', 'lgúica', 'lgiaca', 'lgibca', 'lgicca', 'lgidca', 'lgieca', 'lgifca', 'lgigca', 'lgihca', 'lgiica', 'lgijca', 'lgikca', 'lgilca', 'lgimca', 'lginca', 'lgiñca', 'lgioca', 'lgipca', 'lgiqca', 'lgirca', 'lgisca', 'lgitca', 'lgiuca', 'lgivca', 'lgiwca', 'lgixca', 'lgiyca', 'lgizca', 'lgiáca', 'lgiéca', 'lgiíca', 'lgióca', 'lgiúca', 'lgicaa', 'lgicba', 'lgicca', 'lgicda', 'lgicea', 'lgicfa', 'lgicga', 'lgicha', 'lgicia', 'lgicja', 'lgicka', 'lgicla', 'lgicma', 'lgicna', 'lgicña', 'lgicoa', 'lgicpa', 'lgicqa', 'lgicra', 'lgicsa', 'lgicta', 'lgicua', 'lgicva', 'lgicwa', 'lgicxa', 'lgicya', 'lgicza', 'lgicáa', 'lgicéa', 'lgicía', 'lgicóa', 'lgicúa', 'lgicaa', 'lgicab', 'lgicac', 'lgicad', 'lgicae', 'lgicaf', 'lgicag', 'lgicah', 'lgicai', 'lgicaj', 'lgicak', 'lgical', 'lgicam', 'lgican', 'lgicañ', 'lgicao', 'lgicap', 'lgicaq', 'lgicar', 'lgicas', 'lgicat', 'lgicau', 'lgicav', 'lgicaw', 'lgicax', 'lgicay', 'lgicaz', 'lgicaá', 'lgicaé', 'lgicaí', 'lgicaó', 'lgicaú']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Corrector"
      ],
      "metadata": {
        "id": "eNByqfSFrD2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def corrector(palabra):\n",
        "\n",
        "  palabras_generadas = generar_palabras(palabra)\n",
        "  palabra_corregida = max(palabras_generadas, key=probabilidad)\n",
        "  return palabra_corregida"
      ],
      "metadata": {
        "id": "pbSCZpUmox0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frecuencia = nltk.FreqDist(palabras_normalizadas)\n",
        "frecuencia.most_common(10)\n",
        "total_palabras = len(palabras_normalizadas)"
      ],
      "metadata": {
        "id": "AABknQrbrSYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#construyendo funcion de probabilidad\n",
        "def probabilidad(palabra_generada):\n",
        "  return frecuencia[palabra_generada]/total_palabras"
      ],
      "metadata": {
        "id": "xXdAVRj3q95S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corrector('lgica')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "9wDEdwYwsLsc",
        "outputId": "8a12f1f8-e564-4a6f-91dd-8bb09677e752"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'lógica'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo que aprendimos en esta aula:\n",
        "\n",
        "A construir un algoritmo capaz de corregir palabras que tienen una letra faltante\n",
        "\n",
        "Implementar la función de adición de letras y separación de palabras\n",
        "\n",
        "Implementar la función max() para seleccionar la palabra con mayor probabilidad de aparecer en el corpus\n",
        "\n",
        "A calcular la distribución de frecuencia de las palabras el corpus con nltk.FreqDist"
      ],
      "metadata": {
        "id": "L1ApAPRjoxRD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluador"
      ],
      "metadata": {
        "id": "KuTzZxvEYr3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def crear_datos_prueba(nombre_archivo):\n",
        "  lista_pruebas = []\n",
        "  f = open(nombre_archivo, 'r')\n",
        "  for fila in f:\n",
        "    palabra_correcta, palabra_incorrecta = fila.split()\n",
        "    lista_pruebas.append((palabra_correcta,palabra_incorrecta))\n",
        "  f.close()\n",
        "  return lista_pruebas\n",
        "\n",
        "\n",
        "lista_pruebas = crear_datos_prueba('palabras_pruebas.txt')\n"
      ],
      "metadata": {
        "id": "ijx3NQleZKH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluador(pruebas):\n",
        "  numero_palabras = len(pruebas)\n",
        "  aciertos = 0\n",
        "  for palabra_correcta,palabra_incorrecta in pruebas:\n",
        "    palabra_corregida = corrector(palabra_incorrecta)\n",
        "    if palabra_corregida == palabra_correcta:\n",
        "      aciertos +=1\n",
        "  tasa_acierto = round(aciertos*100/numero_palabras,2)\n",
        "  print(f'La tasa de acierto es: {tasa_acierto}% de {numero_palabras} palabras')\n",
        "\n",
        "\n",
        "evaluador(lista_pruebas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lc4hpAqlYsPV",
        "outputId": "1e941022-1b9c-4c0e-d5d0-f90d4d0b96e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La tasa de acierto es: 5.14% de 175 palabras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo que aprendimos en esta aula:\n",
        "\n",
        "A construir una función para evaluar la calidad de nuestro corrector\n",
        "\n",
        "Utilizamos una base de prueba para validar la calidad de nuestro corrector\n",
        "\n",
        "Calcular la tasa de asertividad de nuestro corrector"
      ],
      "metadata": {
        "id": "4t9UGoAibtVy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Operacion de eliminacion"
      ],
      "metadata": {
        "id": "HYiLqK-5crMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eliminar_caracteres(partes):\n",
        "  nuevas_palabras = []\n",
        "\n",
        "  for I,D in partes:\n",
        "    nuevas_palabras.append(I +  D[1:])\n",
        "  return nuevas_palabras"
      ],
      "metadata": {
        "id": "qXwID3lbcrsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generar_palabras(palabra):\n",
        "  partes = []\n",
        "  for i in range(len(palabra)+1):\n",
        "    partes.append((palabra[:i],palabra[i:]))\n",
        "    palabras_generadas = adicionar_letras(partes)\n",
        "    palabras_generadas += eliminar_caracteres(partes)\n",
        "  return palabras_generadas"
      ],
      "metadata": {
        "id": "7p8nuQowdLc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generar_palabras('loigica'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jd51xdCHdzBx",
        "outputId": "24c130a7-7e88-459d-fdec-e7015921c1dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['aloigica', 'bloigica', 'cloigica', 'dloigica', 'eloigica', 'floigica', 'gloigica', 'hloigica', 'iloigica', 'jloigica', 'kloigica', 'lloigica', 'mloigica', 'nloigica', 'ñloigica', 'oloigica', 'ploigica', 'qloigica', 'rloigica', 'sloigica', 'tloigica', 'uloigica', 'vloigica', 'wloigica', 'xloigica', 'yloigica', 'zloigica', 'áloigica', 'éloigica', 'íloigica', 'óloigica', 'úloigica', 'laoigica', 'lboigica', 'lcoigica', 'ldoigica', 'leoigica', 'lfoigica', 'lgoigica', 'lhoigica', 'lioigica', 'ljoigica', 'lkoigica', 'lloigica', 'lmoigica', 'lnoigica', 'lñoigica', 'looigica', 'lpoigica', 'lqoigica', 'lroigica', 'lsoigica', 'ltoigica', 'luoigica', 'lvoigica', 'lwoigica', 'lxoigica', 'lyoigica', 'lzoigica', 'láoigica', 'léoigica', 'líoigica', 'lóoigica', 'lúoigica', 'loaigica', 'lobigica', 'locigica', 'lodigica', 'loeigica', 'lofigica', 'logigica', 'lohigica', 'loiigica', 'lojigica', 'lokigica', 'loligica', 'lomigica', 'lonigica', 'loñigica', 'looigica', 'lopigica', 'loqigica', 'lorigica', 'losigica', 'lotigica', 'louigica', 'lovigica', 'lowigica', 'loxigica', 'loyigica', 'lozigica', 'loáigica', 'loéigica', 'loíigica', 'loóigica', 'loúigica', 'loiagica', 'loibgica', 'loicgica', 'loidgica', 'loiegica', 'loifgica', 'loiggica', 'loihgica', 'loiigica', 'loijgica', 'loikgica', 'loilgica', 'loimgica', 'loingica', 'loiñgica', 'loiogica', 'loipgica', 'loiqgica', 'loirgica', 'loisgica', 'loitgica', 'loiugica', 'loivgica', 'loiwgica', 'loixgica', 'loiygica', 'loizgica', 'loiágica', 'loiégica', 'loiígica', 'loiógica', 'loiúgica', 'loigaica', 'loigbica', 'loigcica', 'loigdica', 'loigeica', 'loigfica', 'loiggica', 'loighica', 'loigiica', 'loigjica', 'loigkica', 'loiglica', 'loigmica', 'loignica', 'loigñica', 'loigoica', 'loigpica', 'loigqica', 'loigrica', 'loigsica', 'loigtica', 'loiguica', 'loigvica', 'loigwica', 'loigxica', 'loigyica', 'loigzica', 'loigáica', 'loigéica', 'loigíica', 'loigóica', 'loigúica', 'loigiaca', 'loigibca', 'loigicca', 'loigidca', 'loigieca', 'loigifca', 'loigigca', 'loigihca', 'loigiica', 'loigijca', 'loigikca', 'loigilca', 'loigimca', 'loiginca', 'loigiñca', 'loigioca', 'loigipca', 'loigiqca', 'loigirca', 'loigisca', 'loigitca', 'loigiuca', 'loigivca', 'loigiwca', 'loigixca', 'loigiyca', 'loigizca', 'loigiáca', 'loigiéca', 'loigiíca', 'loigióca', 'loigiúca', 'loigicaa', 'loigicba', 'loigicca', 'loigicda', 'loigicea', 'loigicfa', 'loigicga', 'loigicha', 'loigicia', 'loigicja', 'loigicka', 'loigicla', 'loigicma', 'loigicna', 'loigicña', 'loigicoa', 'loigicpa', 'loigicqa', 'loigicra', 'loigicsa', 'loigicta', 'loigicua', 'loigicva', 'loigicwa', 'loigicxa', 'loigicya', 'loigicza', 'loigicáa', 'loigicéa', 'loigicía', 'loigicóa', 'loigicúa', 'loigicaa', 'loigicab', 'loigicac', 'loigicad', 'loigicae', 'loigicaf', 'loigicag', 'loigicah', 'loigicai', 'loigicaj', 'loigicak', 'loigical', 'loigicam', 'loigican', 'loigicañ', 'loigicao', 'loigicap', 'loigicaq', 'loigicar', 'loigicas', 'loigicat', 'loigicau', 'loigicav', 'loigicaw', 'loigicax', 'loigicay', 'loigicaz', 'loigicaá', 'loigicaé', 'loigicaí', 'loigicaó', 'loigicaú', 'oigica', 'ligica', 'logica', 'loiica', 'loigca', 'loigia', 'loigic', 'loigica']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluador(lista_pruebas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kkqd91w3d7jA",
        "outputId": "a17d8189-7e9f-40cd-a3c7-6edb155dd146"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La tasa de acierto es: 38.29% de 175 palabras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo que aprendimos en esta aula:\n",
        "\n",
        "A construir un algoritmo capaz de corregir palabras que tienen una letra extra o por demás\n",
        "\n",
        "Implementar la función de eliminación de caracteres"
      ],
      "metadata": {
        "id": "yQXb3oaaeMbx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Operacion de alteracion"
      ],
      "metadata": {
        "id": "jzG3ir0Pebmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Operacion de alteracion\n",
        "def alterar_caracteres(partes):\n",
        "  letras = 'abcdefghijklmnñopqrstuvwxyzáéíóú'\n",
        "  nuevas_palabras = []\n",
        "\n",
        "  for I,D in partes:\n",
        "    for letra in letras:\n",
        "      nuevas_palabras.append(I + letra + D[1:])\n",
        "  return nuevas_palabras"
      ],
      "metadata": {
        "id": "qgCrMpH4eb_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generar_palabras(palabra):\n",
        "  partes = []\n",
        "  for i in range(len(palabra)+1):\n",
        "    partes.append((palabra[:i],palabra[i:]))\n",
        "    palabras_generadas = adicionar_letras(partes)\n",
        "    palabras_generadas += eliminar_caracteres(partes)\n",
        "    palabras_generadas += alterar_caracteres(partes)\n",
        "  return palabras_generadas"
      ],
      "metadata": {
        "id": "Q_nFNEQtfcGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generar_palabras('lígica'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWmKJ96CfnCc",
        "outputId": "1fff4018-acc9-4069-cd6b-22612d564ee9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['alígica', 'blígica', 'clígica', 'dlígica', 'elígica', 'flígica', 'glígica', 'hlígica', 'ilígica', 'jlígica', 'klígica', 'llígica', 'mlígica', 'nlígica', 'ñlígica', 'olígica', 'plígica', 'qlígica', 'rlígica', 'slígica', 'tlígica', 'ulígica', 'vlígica', 'wlígica', 'xlígica', 'ylígica', 'zlígica', 'álígica', 'élígica', 'ílígica', 'ólígica', 'úlígica', 'laígica', 'lbígica', 'lcígica', 'ldígica', 'leígica', 'lfígica', 'lgígica', 'lhígica', 'liígica', 'ljígica', 'lkígica', 'llígica', 'lmígica', 'lnígica', 'lñígica', 'loígica', 'lpígica', 'lqígica', 'lrígica', 'lsígica', 'ltígica', 'luígica', 'lvígica', 'lwígica', 'lxígica', 'lyígica', 'lzígica', 'láígica', 'léígica', 'líígica', 'lóígica', 'lúígica', 'líagica', 'líbgica', 'lícgica', 'lídgica', 'líegica', 'lífgica', 'líggica', 'líhgica', 'líigica', 'líjgica', 'líkgica', 'lílgica', 'límgica', 'língica', 'líñgica', 'líogica', 'lípgica', 'líqgica', 'lírgica', 'lísgica', 'lítgica', 'líugica', 'lívgica', 'líwgica', 'líxgica', 'líygica', 'lízgica', 'líágica', 'líégica', 'líígica', 'líógica', 'líúgica', 'lígaica', 'lígbica', 'lígcica', 'lígdica', 'lígeica', 'lígfica', 'líggica', 'líghica', 'lígiica', 'lígjica', 'lígkica', 'líglica', 'lígmica', 'lígnica', 'lígñica', 'lígoica', 'lígpica', 'lígqica', 'lígrica', 'lígsica', 'lígtica', 'líguica', 'lígvica', 'lígwica', 'lígxica', 'lígyica', 'lígzica', 'lígáica', 'lígéica', 'lígíica', 'lígóica', 'lígúica', 'lígiaca', 'lígibca', 'lígicca', 'lígidca', 'lígieca', 'lígifca', 'lígigca', 'lígihca', 'lígiica', 'lígijca', 'lígikca', 'lígilca', 'lígimca', 'líginca', 'lígiñca', 'lígioca', 'lígipca', 'lígiqca', 'lígirca', 'lígisca', 'lígitca', 'lígiuca', 'lígivca', 'lígiwca', 'lígixca', 'lígiyca', 'lígizca', 'lígiáca', 'lígiéca', 'lígiíca', 'lígióca', 'lígiúca', 'lígicaa', 'lígicba', 'lígicca', 'lígicda', 'lígicea', 'lígicfa', 'lígicga', 'lígicha', 'lígicia', 'lígicja', 'lígicka', 'lígicla', 'lígicma', 'lígicna', 'lígicña', 'lígicoa', 'lígicpa', 'lígicqa', 'lígicra', 'lígicsa', 'lígicta', 'lígicua', 'lígicva', 'lígicwa', 'lígicxa', 'lígicya', 'lígicza', 'lígicáa', 'lígicéa', 'lígicía', 'lígicóa', 'lígicúa', 'lígicaa', 'lígicab', 'lígicac', 'lígicad', 'lígicae', 'lígicaf', 'lígicag', 'lígicah', 'lígicai', 'lígicaj', 'lígicak', 'lígical', 'lígicam', 'lígican', 'lígicañ', 'lígicao', 'lígicap', 'lígicaq', 'lígicar', 'lígicas', 'lígicat', 'lígicau', 'lígicav', 'lígicaw', 'lígicax', 'lígicay', 'lígicaz', 'lígicaá', 'lígicaé', 'lígicaí', 'lígicaó', 'lígicaú', 'ígica', 'lgica', 'líica', 'lígca', 'lígia', 'lígic', 'lígica', 'aígica', 'bígica', 'cígica', 'dígica', 'eígica', 'fígica', 'gígica', 'hígica', 'iígica', 'jígica', 'kígica', 'lígica', 'mígica', 'nígica', 'ñígica', 'oígica', 'pígica', 'qígica', 'rígica', 'sígica', 'tígica', 'uígica', 'vígica', 'wígica', 'xígica', 'yígica', 'zígica', 'áígica', 'éígica', 'íígica', 'óígica', 'úígica', 'lagica', 'lbgica', 'lcgica', 'ldgica', 'legica', 'lfgica', 'lggica', 'lhgica', 'ligica', 'ljgica', 'lkgica', 'llgica', 'lmgica', 'lngica', 'lñgica', 'logica', 'lpgica', 'lqgica', 'lrgica', 'lsgica', 'ltgica', 'lugica', 'lvgica', 'lwgica', 'lxgica', 'lygica', 'lzgica', 'lágica', 'légica', 'lígica', 'lógica', 'lúgica', 'líaica', 'líbica', 'lícica', 'lídica', 'líeica', 'lífica', 'lígica', 'líhica', 'líiica', 'líjica', 'líkica', 'lílica', 'límica', 'línica', 'líñica', 'líoica', 'lípica', 'líqica', 'lírica', 'lísica', 'lítica', 'líuica', 'lívica', 'líwica', 'líxica', 'líyica', 'lízica', 'líáica', 'líéica', 'lííica', 'líóica', 'líúica', 'lígaca', 'lígbca', 'lígcca', 'lígdca', 'lígeca', 'lígfca', 'líggca', 'líghca', 'lígica', 'lígjca', 'lígkca', 'líglca', 'lígmca', 'lígnca', 'lígñca', 'lígoca', 'lígpca', 'lígqca', 'lígrca', 'lígsca', 'lígtca', 'líguca', 'lígvca', 'lígwca', 'lígxca', 'lígyca', 'lígzca', 'lígáca', 'lígéca', 'lígíca', 'lígóca', 'lígúca', 'lígiaa', 'lígiba', 'lígica', 'lígida', 'lígiea', 'lígifa', 'lígiga', 'lígiha', 'lígiia', 'lígija', 'lígika', 'lígila', 'lígima', 'lígina', 'lígiña', 'lígioa', 'lígipa', 'lígiqa', 'lígira', 'lígisa', 'lígita', 'lígiua', 'lígiva', 'lígiwa', 'lígixa', 'lígiya', 'lígiza', 'lígiáa', 'lígiéa', 'lígiía', 'lígióa', 'lígiúa', 'lígica', 'lígicb', 'lígicc', 'lígicd', 'lígice', 'lígicf', 'lígicg', 'lígich', 'lígici', 'lígicj', 'lígick', 'lígicl', 'lígicm', 'lígicn', 'lígicñ', 'lígico', 'lígicp', 'lígicq', 'lígicr', 'lígics', 'lígict', 'lígicu', 'lígicv', 'lígicw', 'lígicx', 'lígicy', 'lígicz', 'lígicá', 'lígicé', 'lígicí', 'lígicó', 'lígicú', 'lígicaa', 'lígicab', 'lígicac', 'lígicad', 'lígicae', 'lígicaf', 'lígicag', 'lígicah', 'lígicai', 'lígicaj', 'lígicak', 'lígical', 'lígicam', 'lígican', 'lígicañ', 'lígicao', 'lígicap', 'lígicaq', 'lígicar', 'lígicas', 'lígicat', 'lígicau', 'lígicav', 'lígicaw', 'lígicax', 'lígicay', 'lígicaz', 'lígicaá', 'lígicaé', 'lígicaí', 'lígicaó', 'lígicaú']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluador(lista_pruebas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCnDLB74ftPl",
        "outputId": "21d182ca-7294-4725-d85c-34fa31d73e23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La tasa de acierto es: 64.57% de 175 palabras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo que aprendimos en esta aula:\n",
        "\n",
        "Evaluamos un nuevo escenario de error en el proceso de digitación\n",
        "\n",
        "Implementamos la función cambiar letras, cuando uno de los caracteres de la palabra fue alterado involuntariamente por otro carácter\n",
        "\n",
        "Calculamos nuevamente la tasa de asertividad para medir la mejora gradual de la asertividad"
      ],
      "metadata": {
        "id": "zZFlmEazgD05"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Operacion de inversion"
      ],
      "metadata": {
        "id": "xZpoA_PtgRqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def invertir_caracteres(partes):\n",
        "  nuevas_palabras = []\n",
        "\n",
        "  for I,D in partes:\n",
        "    if len(D) > 1:\n",
        "      nuevas_palabras.append(I + D[1] + D[0] + D[2:])\n",
        "  return nuevas_palabras"
      ],
      "metadata": {
        "id": "TTeLTkzPgSE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generar_palabras(palabra):\n",
        "  partes = []\n",
        "  for i in range(len(palabra)+1):\n",
        "    partes.append((palabra[:i],palabra[i:]))\n",
        "    palabras_generadas = adicionar_letras(partes)\n",
        "    palabras_generadas += eliminar_caracteres(partes)\n",
        "    palabras_generadas += alterar_caracteres(partes)\n",
        "    palabras_generadas += invertir_caracteres(partes)\n",
        "  return palabras_generadas"
      ],
      "metadata": {
        "id": "3QcXw_Eyhtnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generar_palabras('lgoíca'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soYAkUxwh0U2",
        "outputId": "90a93da9-6652-47fd-b3e4-ee9059170ded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['algoíca', 'blgoíca', 'clgoíca', 'dlgoíca', 'elgoíca', 'flgoíca', 'glgoíca', 'hlgoíca', 'ilgoíca', 'jlgoíca', 'klgoíca', 'llgoíca', 'mlgoíca', 'nlgoíca', 'ñlgoíca', 'olgoíca', 'plgoíca', 'qlgoíca', 'rlgoíca', 'slgoíca', 'tlgoíca', 'ulgoíca', 'vlgoíca', 'wlgoíca', 'xlgoíca', 'ylgoíca', 'zlgoíca', 'álgoíca', 'élgoíca', 'ílgoíca', 'ólgoíca', 'úlgoíca', 'lagoíca', 'lbgoíca', 'lcgoíca', 'ldgoíca', 'legoíca', 'lfgoíca', 'lggoíca', 'lhgoíca', 'ligoíca', 'ljgoíca', 'lkgoíca', 'llgoíca', 'lmgoíca', 'lngoíca', 'lñgoíca', 'logoíca', 'lpgoíca', 'lqgoíca', 'lrgoíca', 'lsgoíca', 'ltgoíca', 'lugoíca', 'lvgoíca', 'lwgoíca', 'lxgoíca', 'lygoíca', 'lzgoíca', 'lágoíca', 'légoíca', 'lígoíca', 'lógoíca', 'lúgoíca', 'lgaoíca', 'lgboíca', 'lgcoíca', 'lgdoíca', 'lgeoíca', 'lgfoíca', 'lggoíca', 'lghoíca', 'lgioíca', 'lgjoíca', 'lgkoíca', 'lgloíca', 'lgmoíca', 'lgnoíca', 'lgñoíca', 'lgooíca', 'lgpoíca', 'lgqoíca', 'lgroíca', 'lgsoíca', 'lgtoíca', 'lguoíca', 'lgvoíca', 'lgwoíca', 'lgxoíca', 'lgyoíca', 'lgzoíca', 'lgáoíca', 'lgéoíca', 'lgíoíca', 'lgóoíca', 'lgúoíca', 'lgoaíca', 'lgobíca', 'lgocíca', 'lgodíca', 'lgoeíca', 'lgofíca', 'lgogíca', 'lgohíca', 'lgoiíca', 'lgojíca', 'lgokíca', 'lgolíca', 'lgomíca', 'lgoníca', 'lgoñíca', 'lgooíca', 'lgopíca', 'lgoqíca', 'lgoríca', 'lgosíca', 'lgotíca', 'lgouíca', 'lgovíca', 'lgowíca', 'lgoxíca', 'lgoyíca', 'lgozíca', 'lgoáíca', 'lgoéíca', 'lgoííca', 'lgoóíca', 'lgoúíca', 'lgoíaca', 'lgoíbca', 'lgoícca', 'lgoídca', 'lgoíeca', 'lgoífca', 'lgoígca', 'lgoíhca', 'lgoíica', 'lgoíjca', 'lgoíkca', 'lgoílca', 'lgoímca', 'lgoínca', 'lgoíñca', 'lgoíoca', 'lgoípca', 'lgoíqca', 'lgoírca', 'lgoísca', 'lgoítca', 'lgoíuca', 'lgoívca', 'lgoíwca', 'lgoíxca', 'lgoíyca', 'lgoízca', 'lgoíáca', 'lgoíéca', 'lgoííca', 'lgoíóca', 'lgoíúca', 'lgoícaa', 'lgoícba', 'lgoícca', 'lgoícda', 'lgoícea', 'lgoícfa', 'lgoícga', 'lgoícha', 'lgoícia', 'lgoícja', 'lgoícka', 'lgoícla', 'lgoícma', 'lgoícna', 'lgoícña', 'lgoícoa', 'lgoícpa', 'lgoícqa', 'lgoícra', 'lgoícsa', 'lgoícta', 'lgoícua', 'lgoícva', 'lgoícwa', 'lgoícxa', 'lgoícya', 'lgoícza', 'lgoícáa', 'lgoícéa', 'lgoícía', 'lgoícóa', 'lgoícúa', 'lgoícaa', 'lgoícab', 'lgoícac', 'lgoícad', 'lgoícae', 'lgoícaf', 'lgoícag', 'lgoícah', 'lgoícai', 'lgoícaj', 'lgoícak', 'lgoícal', 'lgoícam', 'lgoícan', 'lgoícañ', 'lgoícao', 'lgoícap', 'lgoícaq', 'lgoícar', 'lgoícas', 'lgoícat', 'lgoícau', 'lgoícav', 'lgoícaw', 'lgoícax', 'lgoícay', 'lgoícaz', 'lgoícaá', 'lgoícaé', 'lgoícaí', 'lgoícaó', 'lgoícaú', 'goíca', 'loíca', 'lgíca', 'lgoca', 'lgoía', 'lgoíc', 'lgoíca', 'agoíca', 'bgoíca', 'cgoíca', 'dgoíca', 'egoíca', 'fgoíca', 'ggoíca', 'hgoíca', 'igoíca', 'jgoíca', 'kgoíca', 'lgoíca', 'mgoíca', 'ngoíca', 'ñgoíca', 'ogoíca', 'pgoíca', 'qgoíca', 'rgoíca', 'sgoíca', 'tgoíca', 'ugoíca', 'vgoíca', 'wgoíca', 'xgoíca', 'ygoíca', 'zgoíca', 'ágoíca', 'égoíca', 'ígoíca', 'ógoíca', 'úgoíca', 'laoíca', 'lboíca', 'lcoíca', 'ldoíca', 'leoíca', 'lfoíca', 'lgoíca', 'lhoíca', 'lioíca', 'ljoíca', 'lkoíca', 'lloíca', 'lmoíca', 'lnoíca', 'lñoíca', 'looíca', 'lpoíca', 'lqoíca', 'lroíca', 'lsoíca', 'ltoíca', 'luoíca', 'lvoíca', 'lwoíca', 'lxoíca', 'lyoíca', 'lzoíca', 'láoíca', 'léoíca', 'líoíca', 'lóoíca', 'lúoíca', 'lgaíca', 'lgbíca', 'lgcíca', 'lgdíca', 'lgeíca', 'lgfíca', 'lggíca', 'lghíca', 'lgiíca', 'lgjíca', 'lgkíca', 'lglíca', 'lgmíca', 'lgníca', 'lgñíca', 'lgoíca', 'lgpíca', 'lgqíca', 'lgríca', 'lgsíca', 'lgtíca', 'lguíca', 'lgvíca', 'lgwíca', 'lgxíca', 'lgyíca', 'lgzíca', 'lgáíca', 'lgéíca', 'lgííca', 'lgóíca', 'lgúíca', 'lgoaca', 'lgobca', 'lgocca', 'lgodca', 'lgoeca', 'lgofca', 'lgogca', 'lgohca', 'lgoica', 'lgojca', 'lgokca', 'lgolca', 'lgomca', 'lgonca', 'lgoñca', 'lgooca', 'lgopca', 'lgoqca', 'lgorca', 'lgosca', 'lgotca', 'lgouca', 'lgovca', 'lgowca', 'lgoxca', 'lgoyca', 'lgozca', 'lgoáca', 'lgoéca', 'lgoíca', 'lgoóca', 'lgoúca', 'lgoíaa', 'lgoíba', 'lgoíca', 'lgoída', 'lgoíea', 'lgoífa', 'lgoíga', 'lgoíha', 'lgoíia', 'lgoíja', 'lgoíka', 'lgoíla', 'lgoíma', 'lgoína', 'lgoíña', 'lgoíoa', 'lgoípa', 'lgoíqa', 'lgoíra', 'lgoísa', 'lgoíta', 'lgoíua', 'lgoíva', 'lgoíwa', 'lgoíxa', 'lgoíya', 'lgoíza', 'lgoíáa', 'lgoíéa', 'lgoíía', 'lgoíóa', 'lgoíúa', 'lgoíca', 'lgoícb', 'lgoícc', 'lgoícd', 'lgoíce', 'lgoícf', 'lgoícg', 'lgoích', 'lgoíci', 'lgoícj', 'lgoíck', 'lgoícl', 'lgoícm', 'lgoícn', 'lgoícñ', 'lgoíco', 'lgoícp', 'lgoícq', 'lgoícr', 'lgoícs', 'lgoíct', 'lgoícu', 'lgoícv', 'lgoícw', 'lgoícx', 'lgoícy', 'lgoícz', 'lgoícá', 'lgoícé', 'lgoící', 'lgoícó', 'lgoícú', 'lgoícaa', 'lgoícab', 'lgoícac', 'lgoícad', 'lgoícae', 'lgoícaf', 'lgoícag', 'lgoícah', 'lgoícai', 'lgoícaj', 'lgoícak', 'lgoícal', 'lgoícam', 'lgoícan', 'lgoícañ', 'lgoícao', 'lgoícap', 'lgoícaq', 'lgoícar', 'lgoícas', 'lgoícat', 'lgoícau', 'lgoícav', 'lgoícaw', 'lgoícax', 'lgoícay', 'lgoícaz', 'lgoícaá', 'lgoícaé', 'lgoícaí', 'lgoícaó', 'lgoícaú', 'gloíca', 'logíca', 'lgíoca', 'lgocía', 'lgoíac']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluador(lista_pruebas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmYITh6Gh7Re",
        "outputId": "c92213cc-1c34-4c9a-e263-5bd615131d7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La tasa de acierto es: 65.71% de 175 palabras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Limitacion del corrector"
      ],
      "metadata": {
        "id": "FWgbOPaoifRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluador(pruebas, vocabulario):\n",
        "  numero_palabras = len(pruebas)\n",
        "  aciertos = 0\n",
        "  desconocidas = 0\n",
        "  for palabra_correcta,palabra_incorrecta in pruebas:\n",
        "    palabra_corregida = corrector(palabra_incorrecta)\n",
        "    desconocidas += (palabra_correcta not in vocabulario)\n",
        "    if palabra_corregida == palabra_correcta:\n",
        "      aciertos +=1\n",
        "  tasa_acierto = round(aciertos*100/numero_palabras,2)\n",
        "  tasa_desconocidas = round(desconocidas*100/numero_palabras,2)\n",
        "  print(f'La tasa de acierto es: {tasa_acierto}% de {numero_palabras} palabras')\n",
        "  print(f'La tasa de desconocidas es:{tasa_desconocidas}% de {numero_palabras} palabras')\n",
        "\n",
        "\n",
        "evaluador(lista_pruebas, palabras_unicas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUnZ0hqjiXY-",
        "outputId": "3679d1ea-d6af-4a1a-a26f-9c8c0f0ebf1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La tasa de acierto es: 65.71% de 175 palabras\n",
            "La tasa de desconocidas es:12.0% de 175 palabras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo que aprendimos en esta aula:\n",
        "\n",
        "Finalizamos evaluando un cuarto escenario de error en el proceso de digitacion\n",
        "\n",
        "Implementamos la función invertir letras, cuando dos caracteres vienen\n",
        "invertidos en la palabra\n",
        "Calculamos la tasa final de asertividad de nuestro corrector\n",
        "\n",
        "Calculamos la tasa de palabras desconocidas, uno de los limitadores de la calidad de nuestro corrector"
      ],
      "metadata": {
        "id": "gkUfpC00kWdu"
      }
    }
  ]
}