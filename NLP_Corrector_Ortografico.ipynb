{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMosN1qZ0ui7mE5DPJ0bOPI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdrianCPC/Primeros_pasos_IA/blob/main/NLP_Corrector_Ortografico.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3x7ZpfwaBFpj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importar el corpus"
      ],
      "metadata": {
        "id": "MawrXgB6jiED"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ob9ZYN_-Vbk",
        "outputId": "b2640f85-3fb4-48e4-9c24-eadf979553ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\"HTTP: Diferencias entre GET y POST \"\n",
            "2020-10-21\n",
            "\"Vea las diferencias entre los métodos GET y POST de HTTP. Consulta la funcionalidad de cada uno y cuándo usarlos en la web.\"\n",
            "\"yuri-oliveira\"\n",
            "\"yuri.oliveira@alura.com.br\"\n",
            "\"front-end\"\n",
            "\n",
            "Cuando vamos a acceder a un sistema web, es bastante común pasar por una pantalla de inicio de sesión, en la que ponemos nuestras credenciales para acceder al sistema.\n",
            "Estas informaciones deben ser confidenciales, sin embargo, cuando intenté iniciar sesión en una ap\n"
          ]
        }
      ],
      "source": [
        "with open('textos_articulo.txt', 'r') as f:\n",
        "  articulos = f.read()\n",
        "  print(articulos[:500])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Separando palabras"
      ],
      "metadata": {
        "id": "YODdXBtKjl4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto_ejemplo = ' hola que tal'\n",
        "print(len(texto_ejemplo))\n",
        "palabras = texto_ejemplo.split()\n",
        "print(len(palabras))\n",
        "print(palabras)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghaoyZ_G_crP",
        "outputId": "35273308-2c84-4848-9310-7c3a13d36fea"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13\n",
            "3\n",
            "['hola', 'que', 'tal']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto_ejemplo = ' hola critian, ¿que tal?'\n",
        "print(len(texto_ejemplo))\n",
        "palabras = texto_ejemplo.split()\n",
        "print(len(palabras))\n",
        "print(palabras)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxDunWfS_ui0",
        "outputId": "da3426df-3bf9-4258-e6d7-bff139d3b836"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24\n",
            "4\n",
            "['hola', 'critian,', '¿que', 'tal?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizando para analizar cada palabra, pero aun con split que no permite separar de caractes especiales\n",
        "texto_ejemplo = ' hola critian, ¿que tal?'\n",
        "print(len(texto_ejemplo))\n",
        "tokens = texto_ejemplo.split()\n",
        "print(len(tokens))\n",
        "print(tokens)"
      ],
      "metadata": {
        "id": "d-F4f1q4AD3H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7705aea-fb19-45c8-9ce2-76def6527eca"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24\n",
            "4\n",
            "['hola', 'critian,', '¿que', 'tal?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo que aprendimos en esta aula:\n",
        "\n",
        "El concepto de Procesamiento de Lenguaje Natural (PLN o NLP)\n",
        "\n",
        "En qué consiste un corrector ortográfico\n",
        "\n",
        "Cómo leer un archivo de texto usando python\n",
        "\n",
        "Separar las palabras usando split()"
      ],
      "metadata": {
        "id": "MAekAm5MD0wN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tokenizacion"
      ],
      "metadata": {
        "id": "h1YbysBSjrcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Px8CG-uTjtqK",
        "outputId": "420a6aed-c653-4a06-f170-69683b3fa800"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "palabras_separadas = nltk.tokenize.word_tokenize(texto_ejemplo) #para ingles\n",
        "print(palabras_separadas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyhuteJNj6ej",
        "outputId": "3b109e3a-08b3-4077-c433-52ba77db1019"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hola', 'critian', ',', '¿que', 'tal', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize.toktok import ToktokTokenizer   #usa las funciones en espanol"
      ],
      "metadata": {
        "id": "8yxUKVxEkYpu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "toktok = ToktokTokenizer()\n",
        "palabras_separadas = toktok.tokenize(texto_ejemplo)\n",
        "print(palabras_separadas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcGM3P-fkqdz",
        "outputId": "16197f5b-7701-44ac-97ef-6662bdbe106c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hola', 'critian', ',', '¿', 'que', 'tal', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(palabras_separadas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybWBcQukk5qj",
        "outputId": "bb61286b-e680-439b-cd4a-9f672abc6d40"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Excluyendo caracteres y puntuaciones"
      ],
      "metadata": {
        "id": "Yd4YGdVllcYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def separa_palabras(lista_tokens):\n",
        "  lista_palabras = []\n",
        "  for token in lista_tokens:\n",
        "    if token.isalpha():\n",
        "      lista_palabras.append(token)\n",
        "  return lista_palabras     #contabilizar cuantas palabras en el corpus se tiene"
      ],
      "metadata": {
        "id": "DplCogUUlWRS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "separa_palabras(palabras_separadas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KM5POVDmIQb",
        "outputId": "d61a3e92-c5e9-47ed-e536-03bed22212f4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hola', 'critian', 'que', 'tal']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Contando palabras del corpus"
      ],
      "metadata": {
        "id": "XuTKFYXom93L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "palabras_separadas = toktok.tokenize(articulos)\n",
        "lista_palabras = separa_palabras(palabras_separadas)"
      ],
      "metadata": {
        "id": "j4ZDAHzImV1c"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'La cantidad de palabras en el corpus es de : {len(lista_palabras)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0LZ-rkKnltN",
        "outputId": "619d559b-84d2-475d-f96c-0da11b9c3c9c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La cantidad de palabras en el corpus es de : 40052\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lista_palabras[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fi7OwjTfn3Li",
        "outputId": "b97c778e-2086-4c72-faae-ba5f0827ac37"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['HTTP',\n",
              " 'Diferencias',\n",
              " 'entre',\n",
              " 'GET',\n",
              " 'y',\n",
              " 'POST',\n",
              " 'Vea',\n",
              " 'las',\n",
              " 'diferencias',\n",
              " 'entre',\n",
              " 'los',\n",
              " 'métodos',\n",
              " 'GET',\n",
              " 'y',\n",
              " 'POST',\n",
              " 'de',\n",
              " 'Consulta',\n",
              " 'la',\n",
              " 'funcionalidad',\n",
              " 'de']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Normalizando y eliminando duplicados"
      ],
      "metadata": {
        "id": "iRifwq0foMVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalizar(lista_palabras):\n",
        "  lista_normalizada = []\n",
        "\n",
        "  for palabra in lista_palabras:\n",
        "    lista_normalizada.append(palabra.lower())\n",
        "\n",
        "  return lista_normalizada"
      ],
      "metadata": {
        "id": "CEHJoU2ioZli"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "palabras_normalizadas = normalizar(lista_palabras)\n",
        "print(palabras_normalizadas[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QLuIosno2xt",
        "outputId": "73683488-f981-4a58-d702-e4eb51bada70"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['http', 'diferencias', 'entre', 'get', 'y', 'post', 'vea', 'las', 'diferencias', 'entre', 'los', 'métodos', 'get', 'y', 'post', 'de', 'consulta', 'la', 'funcionalidad', 'de']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#eliminacion duplicados\n",
        "\n",
        "palabras_unicas = set(palabras_normalizadas)\n",
        "print(len(palabras_unicas))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d84UDFlrpG4t",
        "outputId": "01c9d9f5-1643-44de-add3-b9e37956cc7e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo que aprendimos en esta aula:\n",
        "\n",
        "El concepto de tokenización\n",
        "\n",
        "A realizar el proceso de tokenización con las bibliotecas NLTK y toktok\n",
        "\n",
        "Separar caracteres alfabéticos de caracteres especiales con isalpha()\n",
        "\n",
        "Contar caracteres y palabras usando len()\n",
        "\n",
        "Proceso de Normalización con lower()\n",
        "\n",
        "Eliminar duplicados y repetidos con set()"
      ],
      "metadata": {
        "id": "LZ5888J1psIs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Operacion de adicion"
      ],
      "metadata": {
        "id": "omM31LJWiNw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#generar partes\n",
        "\n",
        "\n",
        "\n",
        "def adicionar_letras(partes):\n",
        "  letras = 'abcdefghijklmnñopqrstuvwxyzáéíóú'\n",
        "  nuevas_palabras = []\n",
        "\n",
        "  for I,D in partes:\n",
        "    for letra in letras:\n",
        "      nuevas_palabras.append(I + letra + D)\n",
        "  return nuevas_palabras\n",
        "\n",
        "\n",
        "def generar_palabras(palabra):\n",
        "  partes = []\n",
        "  for i in range(len(palabra)+1):\n",
        "    partes.append((palabra[:i],palabra[i:]))\n",
        "    palabras_generadas = adicionar_letras(partes)\n",
        "  return palabras_generadas\n",
        "\n"
      ],
      "metadata": {
        "id": "eKnEPySciOOw"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "palabra = 'lgica'\n",
        "palabras_generadas = generar_palabras(palabra)\n",
        "print(palabras_generadas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_40eW_SBnxVj",
        "outputId": "7ed1274a-44a1-4c68-bda7-f37b700a6742"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['algica', 'blgica', 'clgica', 'dlgica', 'elgica', 'flgica', 'glgica', 'hlgica', 'ilgica', 'jlgica', 'klgica', 'llgica', 'mlgica', 'nlgica', 'ñlgica', 'olgica', 'plgica', 'qlgica', 'rlgica', 'slgica', 'tlgica', 'ulgica', 'vlgica', 'wlgica', 'xlgica', 'ylgica', 'zlgica', 'álgica', 'élgica', 'ílgica', 'ólgica', 'úlgica', 'lagica', 'lbgica', 'lcgica', 'ldgica', 'legica', 'lfgica', 'lggica', 'lhgica', 'ligica', 'ljgica', 'lkgica', 'llgica', 'lmgica', 'lngica', 'lñgica', 'logica', 'lpgica', 'lqgica', 'lrgica', 'lsgica', 'ltgica', 'lugica', 'lvgica', 'lwgica', 'lxgica', 'lygica', 'lzgica', 'lágica', 'légica', 'lígica', 'lógica', 'lúgica', 'lgaica', 'lgbica', 'lgcica', 'lgdica', 'lgeica', 'lgfica', 'lggica', 'lghica', 'lgiica', 'lgjica', 'lgkica', 'lglica', 'lgmica', 'lgnica', 'lgñica', 'lgoica', 'lgpica', 'lgqica', 'lgrica', 'lgsica', 'lgtica', 'lguica', 'lgvica', 'lgwica', 'lgxica', 'lgyica', 'lgzica', 'lgáica', 'lgéica', 'lgíica', 'lgóica', 'lgúica', 'lgiaca', 'lgibca', 'lgicca', 'lgidca', 'lgieca', 'lgifca', 'lgigca', 'lgihca', 'lgiica', 'lgijca', 'lgikca', 'lgilca', 'lgimca', 'lginca', 'lgiñca', 'lgioca', 'lgipca', 'lgiqca', 'lgirca', 'lgisca', 'lgitca', 'lgiuca', 'lgivca', 'lgiwca', 'lgixca', 'lgiyca', 'lgizca', 'lgiáca', 'lgiéca', 'lgiíca', 'lgióca', 'lgiúca', 'lgicaa', 'lgicba', 'lgicca', 'lgicda', 'lgicea', 'lgicfa', 'lgicga', 'lgicha', 'lgicia', 'lgicja', 'lgicka', 'lgicla', 'lgicma', 'lgicna', 'lgicña', 'lgicoa', 'lgicpa', 'lgicqa', 'lgicra', 'lgicsa', 'lgicta', 'lgicua', 'lgicva', 'lgicwa', 'lgicxa', 'lgicya', 'lgicza', 'lgicáa', 'lgicéa', 'lgicía', 'lgicóa', 'lgicúa', 'lgicaa', 'lgicab', 'lgicac', 'lgicad', 'lgicae', 'lgicaf', 'lgicag', 'lgicah', 'lgicai', 'lgicaj', 'lgicak', 'lgical', 'lgicam', 'lgican', 'lgicañ', 'lgicao', 'lgicap', 'lgicaq', 'lgicar', 'lgicas', 'lgicat', 'lgicau', 'lgicav', 'lgicaw', 'lgicax', 'lgicay', 'lgicaz', 'lgicaá', 'lgicaé', 'lgicaí', 'lgicaó', 'lgicaú']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Corrector"
      ],
      "metadata": {
        "id": "eNByqfSFrD2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def corrector(palabra):\n",
        "\n",
        "  palabras_generadas = generar_palabras(palabra)\n",
        "  palabra_corregida = max(palabras_generadas, key=probabilidad)\n",
        "  return palabra_corregida"
      ],
      "metadata": {
        "id": "pbSCZpUmox0P"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frecuencia = nltk.FreqDist(palabras_normalizadas)\n",
        "frecuencia.most_common(10)\n",
        "total_palabras = len(palabras_normalizadas)"
      ],
      "metadata": {
        "id": "AABknQrbrSYh"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#construyendo funcion de probabilidad\n",
        "def probabilidad(palabra_generada):\n",
        "  return frecuencia[palabra_generada]/total_palabras"
      ],
      "metadata": {
        "id": "xXdAVRj3q95S"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corrector('lgica')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "9wDEdwYwsLsc",
        "outputId": "12a90cab-7114-4714-aa4d-248c6fb45953"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'lógica'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo que aprendimos en esta aula:\n",
        "\n",
        "A construir un algoritmo capaz de corregir palabras que tienen una letra faltante\n",
        "\n",
        "Implementar la función de adición de letras y separación de palabras\n",
        "\n",
        "Implementar la función max() para seleccionar la palabra con mayor probabilidad de aparecer en el corpus\n",
        "\n",
        "A calcular la distribución de frecuencia de las palabras el corpus con nltk.FreqDist"
      ],
      "metadata": {
        "id": "L1ApAPRjoxRD"
      }
    }
  ]
}